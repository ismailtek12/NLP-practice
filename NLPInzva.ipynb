{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887b7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import logging\n",
    "import multiprocessing\n",
    "\n",
    "import faiss\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from datasets import load_dataset\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "from sklearn.decomposition import TruncatedSVD,NMF\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c501e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"arxiv_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59248b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>desired_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0086</td>\n",
       "      <td>Clustering in a stochastic model of one-dimens...</td>\n",
       "      <td>We give a quantitative analysis of clusterin...</td>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0215</td>\n",
       "      <td>The exact asymptotic of the collision time tai...</td>\n",
       "      <td>In this note we consider the time of the col...</td>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0380</td>\n",
       "      <td>Exponential growth rates in a typed branching ...</td>\n",
       "      <td>We study the high temperature phase of a fam...</td>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0398</td>\n",
       "      <td>Renewals for exponentially increasing lifetime...</td>\n",
       "      <td>We show that the number of renewals up to ti...</td>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0405</td>\n",
       "      <td>An invariance principle for semimartingale ref...</td>\n",
       "      <td>Semimartingale reflecting Brownian motions (...</td>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0  0704.0086  Clustering in a stochastic model of one-dimens...   \n",
       "1  0704.0215  The exact asymptotic of the collision time tai...   \n",
       "2  0704.0380  Exponential growth rates in a typed branching ...   \n",
       "3  0704.0398  Renewals for exponentially increasing lifetime...   \n",
       "4  0704.0405  An invariance principle for semimartingale ref...   \n",
       "\n",
       "                                            abstract   categories  \\\n",
       "0    We give a quantitative analysis of clusterin...  ['math.PR']   \n",
       "1    In this note we consider the time of the col...  ['math.PR']   \n",
       "2    We study the high temperature phase of a fam...  ['math.PR']   \n",
       "3    We show that the number of renewals up to ti...  ['math.PR']   \n",
       "4    Semimartingale reflecting Brownian motions (...  ['math.PR']   \n",
       "\n",
       "   desired_categories  \n",
       "0                True  \n",
       "1                True  \n",
       "2                True  \n",
       "3                True  \n",
       "4                True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8e99ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23025, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeff622",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c16de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'Ismail', ',', 'I', 'love', 'data', 'science', '.']\n"
     ]
    }
   ],
   "source": [
    "def tokenize_punc(text):\n",
    "    text=re.findall(r\"([,.!;\\-\\(\\)]|\\b[\\w'.]+\\b)\",text)\n",
    "    return text\n",
    "print(tokenize_punc(\"My name is Ismail, I love data science.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745ad6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My favorite food in this cook book is Rissotto. \n"
     ]
    }
   ],
   "source": [
    "def clean_apostrophes(text):\n",
    "    text = text.replace(\"'\", '')\n",
    "    text = text.replace(\"`\", '')\n",
    "    text = text.replace(\"“\", '')\n",
    "    text = text.replace(\"”\", '')\n",
    "    return text\n",
    "print(clean_apostrophes(\"My favorite food in this cook book is 'Rissotto'. \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca1ba6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Ismail I love data science.\n"
     ]
    }
   ],
   "source": [
    "def clean_punc(text,keep_stop=True):\n",
    "    \n",
    "    if not keep_stop:\n",
    "        text=re.sub(r\"[^\\w\\s]\",\"\",text)\n",
    "    else:\n",
    "        text=re.sub(r\"[^\\w\\s!?.]\",\"\",text)\n",
    "    return text.strip()\n",
    "print(clean_punc(\"My name is Ismail, I love data science.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dd602e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    text=tokenize_punc(text)\n",
    "    text=list(map(lambda x:clean_apostrophes(x),text))\n",
    "    text=list(map(lambda x:clean_punc(x),text))\n",
    "    text=list(map(lambda x:x.lower(),text))\n",
    "    \n",
    "    text=\" \".join(text)\n",
    "    text=text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "056a8739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is ismail  i love data science .\n"
     ]
    }
   ],
   "source": [
    "print(preprocess(\"My name is Ismail, I love data science.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b80d2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40190eaa426b4160b087c7e5fe5ea746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ebef872a874bee8d059b125ad530b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"title_pp\"]=dataset[\"title\"].progress_apply(lambda x: preprocess(x))\n",
    "dataset[\"abstract_pp\"]=dataset[\"abstract\"].progress_apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35dbbb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncores=multiprocessing.cpu_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c99e41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>desired_categories</th>\n",
       "      <th>title_pp</th>\n",
       "      <th>abstract_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0086</td>\n",
       "      <td>Clustering in a stochastic model of one-dimens...</td>\n",
       "      <td>We give a quantitative analysis of clusterin...</td>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>True</td>\n",
       "      <td>clustering in a stochastic model of one  dimen...</td>\n",
       "      <td>we give a quantitative analysis of clustering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0215</td>\n",
       "      <td>The exact asymptotic of the collision time tai...</td>\n",
       "      <td>In this note we consider the time of the col...</td>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>True</td>\n",
       "      <td>the exact asymptotic of the collision time tai...</td>\n",
       "      <td>in this note we consider the time of the colli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0380</td>\n",
       "      <td>Exponential growth rates in a typed branching ...</td>\n",
       "      <td>We study the high temperature phase of a fam...</td>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>True</td>\n",
       "      <td>exponential growth rates in a typed branching ...</td>\n",
       "      <td>we study the high temperature phase of a famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0398</td>\n",
       "      <td>Renewals for exponentially increasing lifetime...</td>\n",
       "      <td>We show that the number of renewals up to ti...</td>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>True</td>\n",
       "      <td>renewals for exponentially increasing lifetime...</td>\n",
       "      <td>we show that the number of renewals up to time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0405</td>\n",
       "      <td>An invariance principle for semimartingale ref...</td>\n",
       "      <td>Semimartingale reflecting Brownian motions (...</td>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>True</td>\n",
       "      <td>an invariance principle for semimartingale ref...</td>\n",
       "      <td>semimartingale reflecting brownian motions  sr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0  0704.0086  Clustering in a stochastic model of one-dimens...   \n",
       "1  0704.0215  The exact asymptotic of the collision time tai...   \n",
       "2  0704.0380  Exponential growth rates in a typed branching ...   \n",
       "3  0704.0398  Renewals for exponentially increasing lifetime...   \n",
       "4  0704.0405  An invariance principle for semimartingale ref...   \n",
       "\n",
       "                                            abstract   categories  \\\n",
       "0    We give a quantitative analysis of clusterin...  ['math.PR']   \n",
       "1    In this note we consider the time of the col...  ['math.PR']   \n",
       "2    We study the high temperature phase of a fam...  ['math.PR']   \n",
       "3    We show that the number of renewals up to ti...  ['math.PR']   \n",
       "4    Semimartingale reflecting Brownian motions (...  ['math.PR']   \n",
       "\n",
       "   desired_categories                                           title_pp  \\\n",
       "0                True  clustering in a stochastic model of one  dimen...   \n",
       "1                True  the exact asymptotic of the collision time tai...   \n",
       "2                True  exponential growth rates in a typed branching ...   \n",
       "3                True  renewals for exponentially increasing lifetime...   \n",
       "4                True  an invariance principle for semimartingale ref...   \n",
       "\n",
       "                                         abstract_pp  \n",
       "0  we give a quantitative analysis of clustering ...  \n",
       "1  in this note we consider the time of the colli...  \n",
       "2  we study the high temperature phase of a famil...  \n",
       "3  we show that the number of renewals up to time...  \n",
       "4  semimartingale reflecting brownian motions  sr...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e94b00",
   "metadata": {},
   "source": [
    "### Preparing for word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba473df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vocab=dataset[\"title_pp\"].tolist()\n",
    "title_vocab=[token for line in title_vocab for token in line.split()]\n",
    "\n",
    "abstract_vocab=dataset[\"title_pp\"].tolist()\n",
    "abstract_vocab=[token for line in abstract_vocab for token in line.split()]\n",
    "\n",
    "title_vocab=collections.Counter(title_vocab)\n",
    "abstract_vocab=collections.Counter(abstract_vocab)\n",
    "\n",
    "vocab=title_vocab+abstract_vocab\n",
    "vocab=dict(sorted(vocab.items(),key=lambda x:x[1],reverse=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e00c92a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'of': 25604,\n",
       " 'the': 16902,\n",
       " 'for': 16396,\n",
       " 'and': 12728,\n",
       " 'a': 11136,\n",
       " 'on': 9310,\n",
       " 'random': 8886,\n",
       " 'with': 8658,\n",
       " 'in': 8344,\n",
       " 'processes': 5850,\n",
       " 'stochastic': 4684,\n",
       " 'to': 3684,\n",
       " 'time': 2746,\n",
       " 'brownian': 2724,\n",
       " 'equations': 2528,\n",
       " 'model': 2358,\n",
       " 'limit': 2332,\n",
       " 'process': 2288,\n",
       " 'markov': 2102,\n",
       " 'by': 1966,\n",
       " 'large': 1916,\n",
       " 'gaussian': 1816,\n",
       " 'motion': 1730,\n",
       " 'an': 1680,\n",
       " 'convergence': 1680,\n",
       " 'l': 1670,\n",
       " 'walks': 1626,\n",
       " 'models': 1600,\n",
       " 'differential': 1596,\n",
       " 'non': 1564,\n",
       " 'dimensional': 1490,\n",
       " 'walk': 1478,\n",
       " 'branching': 1436,\n",
       " 'theorem': 1404,\n",
       " 'fractional': 1344,\n",
       " 'percolation': 1262,\n",
       " 'local': 1188,\n",
       " 'two': 1152,\n",
       " 'distribution': 1148,\n",
       " 'equation': 1136,\n",
       " 'driven': 1116,\n",
       " 'type': 1112,\n",
       " 'deviations': 1098,\n",
       " 'evy': 1098,\n",
       " 'approximation': 1094,\n",
       " 'noise': 1064,\n",
       " 'stable': 1052,\n",
       " 'times': 1048,\n",
       " 'asymptotic': 1040,\n",
       " 'diffusion': 1024,\n",
       " 'applications': 1020,\n",
       " 'distributions': 1018,\n",
       " 'theorems': 1012,\n",
       " 'graphs': 998,\n",
       " 'measures': 998,\n",
       " 'stationary': 974,\n",
       " 'matrices': 966,\n",
       " 'poisson': 960,\n",
       " 'systems': 952,\n",
       " 'trees': 936,\n",
       " 'linear': 914,\n",
       " 'some': 906,\n",
       " 'from': 900,\n",
       " 'infinite': 862,\n",
       " 'space': 856,\n",
       " 'via': 854,\n",
       " 'under': 836,\n",
       " 'chains': 828,\n",
       " 'environment': 824,\n",
       " 'analysis': 812,\n",
       " 'approach': 808,\n",
       " 'solutions': 806,\n",
       " 'dependent': 802,\n",
       " 'continuous': 800,\n",
       " 'one': 794,\n",
       " 'using': 786,\n",
       " 'probability': 784,\n",
       " 'central': 782,\n",
       " 'exponential': 772,\n",
       " 'law': 772,\n",
       " 'based': 766,\n",
       " 'generalized': 756,\n",
       " 'fields': 756,\n",
       " 'optimal': 748,\n",
       " 'bounds': 734,\n",
       " 'critical': 734,\n",
       " 'diffusions': 730,\n",
       " 'strong': 730,\n",
       " 'general': 726,\n",
       " 'asymptotics': 706,\n",
       " 'learning': 704,\n",
       " 'functions': 700,\n",
       " 'inequalities': 698,\n",
       " 'class': 688,\n",
       " 'properties': 684,\n",
       " 'networks': 678,\n",
       " 'point': 674,\n",
       " 'measure': 670,\n",
       " 'field': 670,\n",
       " '1': 670,\n",
       " 'spaces': 664,\n",
       " 'sdes': 660,\n",
       " 'discrete': 656,\n",
       " 'first': 640,\n",
       " 'variables': 638,\n",
       " 'weak': 638,\n",
       " 'multi': 634,\n",
       " 'finite': 630,\n",
       " 'estimates': 620,\n",
       " 'mean': 616,\n",
       " 'application': 610,\n",
       " 'problem': 602,\n",
       " 'self': 592,\n",
       " '.': 592,\n",
       " 'heat': 588,\n",
       " 'rate': 582,\n",
       " 'order': 582,\n",
       " 'principle': 580,\n",
       " 'limits': 574,\n",
       " 'method': 566,\n",
       " 'functional': 564,\n",
       " 'passage': 564,\n",
       " 'symmetric': 562,\n",
       " 'free': 558,\n",
       " 'scaling': 554,\n",
       " 'high': 546,\n",
       " 'backward': 536,\n",
       " 'path': 536,\n",
       " 'estimation': 534,\n",
       " 'spectral': 530,\n",
       " 'boundary': 526,\n",
       " 'theory': 526,\n",
       " 'functionals': 518,\n",
       " 'particle': 516,\n",
       " 'nonlinear': 516,\n",
       " 'drift': 514,\n",
       " 'matrix': 506,\n",
       " 'e': 494,\n",
       " 'heavy': 484,\n",
       " 'behavior': 478,\n",
       " 'tail': 472,\n",
       " 'uniform': 470,\n",
       " 'note': 470,\n",
       " 'density': 466,\n",
       " 'representation': 464,\n",
       " 'inequality': 464,\n",
       " 'martingale': 462,\n",
       " '2': 460,\n",
       " 'approximations': 456,\n",
       " 'at': 454,\n",
       " 'state': 452,\n",
       " 'tree': 448,\n",
       " 'formula': 448,\n",
       " 'jump': 446,\n",
       " 'its': 446,\n",
       " 'partial': 446,\n",
       " 'jumps': 444,\n",
       " 'dynamics': 444,\n",
       " 'probabilities': 442,\n",
       " 'existence': 442,\n",
       " 'multivariate': 440,\n",
       " 'd': 438,\n",
       " 'small': 436,\n",
       " 'range': 436,\n",
       " 'deviation': 434,\n",
       " 'related': 432,\n",
       " 'problems': 432,\n",
       " 'data': 432,\n",
       " 'independent': 430,\n",
       " 'reflected': 430,\n",
       " 'sums': 428,\n",
       " 'long': 420,\n",
       " 'graph': 418,\n",
       " 'growth': 414,\n",
       " 'system': 412,\n",
       " 'uniqueness': 412,\n",
       " 'function': 412,\n",
       " 'fluctuations': 404,\n",
       " 'network': 402,\n",
       " 'image': 400,\n",
       " 'coefficients': 398,\n",
       " 'r': 398,\n",
       " 'dirichlet': 396,\n",
       " 'phase': 396,\n",
       " 'invariant': 396,\n",
       " 'g': 396,\n",
       " 'bsdes': 392,\n",
       " 'transition': 390,\n",
       " 'levy': 390,\n",
       " 'case': 390,\n",
       " 'dimension': 388,\n",
       " 'statistics': 388,\n",
       " 'maximum': 386,\n",
       " 'sparse': 386,\n",
       " 'motions': 384,\n",
       " 'new': 382,\n",
       " 'h': 382,\n",
       " 'p': 376,\n",
       " 'spatial': 376,\n",
       " 'number': 374,\n",
       " 'interacting': 374,\n",
       " 'laws': 370,\n",
       " 'multiple': 368,\n",
       " 'rough': 366,\n",
       " 'bayesian': 366,\n",
       " 'stability': 364,\n",
       " 'probabilistic': 364,\n",
       " 'rates': 360,\n",
       " 'conditions': 360,\n",
       " 'watson': 358,\n",
       " 'kernel': 358,\n",
       " 'simple': 356,\n",
       " 'concentration': 354,\n",
       " 'scale': 352,\n",
       " 'galton': 350,\n",
       " 'wiener': 350,\n",
       " 'associated': 348,\n",
       " 'mixing': 348,\n",
       " 'variation': 346,\n",
       " 'integrals': 346,\n",
       " 'risk': 346,\n",
       " 'convex': 344,\n",
       " 'results': 342,\n",
       " 'o': 340,\n",
       " 'integral': 334,\n",
       " 'their': 330,\n",
       " 'moments': 330,\n",
       " 'solution': 328,\n",
       " 'geometric': 328,\n",
       " 'multidimensional': 326,\n",
       " 'invariance': 324,\n",
       " 'martingales': 324,\n",
       " 'quadratic': 320,\n",
       " 'condition': 320,\n",
       " 'queue': 320,\n",
       " 'between': 320,\n",
       " 'deep': 320,\n",
       " 'valued': 318,\n",
       " 'sequences': 318,\n",
       " 'z': 318,\n",
       " 'numbers': 316,\n",
       " 'mathbb': 312,\n",
       " 'variational': 312,\n",
       " 'regular': 312,\n",
       " 'additive': 310,\n",
       " 'queues': 310,\n",
       " 'variance': 310,\n",
       " 'distance': 308,\n",
       " 'weighted': 308,\n",
       " 'ergodicity': 308,\n",
       " 'regularity': 306,\n",
       " 'conditional': 306,\n",
       " 'quasi': 306,\n",
       " 'sampling': 306,\n",
       " 'parabolic': 306,\n",
       " 'singular': 304,\n",
       " 'planar': 302,\n",
       " 'paths': 302,\n",
       " 'sets': 300,\n",
       " 'moment': 300,\n",
       " 'positive': 298,\n",
       " 'zero': 292,\n",
       " 'multiplicative': 290,\n",
       " 'directed': 290,\n",
       " 'inhomogeneous': 290,\n",
       " 'property': 290,\n",
       " 'control': 288,\n",
       " 'hitting': 288,\n",
       " 'moderate': 288,\n",
       " 'sample': 288,\n",
       " 'iterated': 286,\n",
       " 'normal': 282,\n",
       " 'series': 282,\n",
       " 'continuity': 282,\n",
       " 'characterization': 274,\n",
       " 'stopping': 272,\n",
       " 'regime': 272,\n",
       " 'spdes': 272,\n",
       " 'negative': 270,\n",
       " 'polynomials': 270,\n",
       " 'second': 270,\n",
       " 'dimensions': 268,\n",
       " 'images': 268,\n",
       " 'ergodic': 266,\n",
       " 'structure': 266,\n",
       " 'fast': 266,\n",
       " 'alpha': 264,\n",
       " 'semi': 264,\n",
       " 'calculus': 262,\n",
       " 'ornstein': 262,\n",
       " 'uhlenbeck': 262,\n",
       " 'dynamic': 262,\n",
       " 'contact': 260,\n",
       " 'exact': 258,\n",
       " 'renewal': 258,\n",
       " 'points': 258,\n",
       " 'selection': 258,\n",
       " 'empirical': 256,\n",
       " 'evolution': 252,\n",
       " 'supercritical': 250,\n",
       " 'set': 250,\n",
       " 'markovian': 250,\n",
       " 'neural': 250,\n",
       " 'densities': 244,\n",
       " 'tailed': 244,\n",
       " 'real': 242,\n",
       " 'homogeneous': 242,\n",
       " 'n': 242,\n",
       " 'flows': 242,\n",
       " 'inference': 242,\n",
       " 'as': 242,\n",
       " 'i': 240,\n",
       " 'ii': 240,\n",
       " 'vy': 238,\n",
       " 'parameter': 236,\n",
       " 'it': 234,\n",
       " 'beta': 234,\n",
       " 'maximal': 234,\n",
       " 'clustering': 232,\n",
       " '2d': 232,\n",
       " 'gradient': 232,\n",
       " 'regression': 230,\n",
       " 'algorithm': 230,\n",
       " 'entropy': 230,\n",
       " 'quenched': 228,\n",
       " 'chain': 228,\n",
       " 'similar': 228,\n",
       " 'flow': 228,\n",
       " 'super': 226,\n",
       " 'operators': 226,\n",
       " 'm': 226,\n",
       " 'comparison': 224,\n",
       " 'varying': 224,\n",
       " 'is': 222,\n",
       " 'line': 222,\n",
       " 'error': 222,\n",
       " 'exit': 222,\n",
       " 'bound': 222,\n",
       " 'lower': 220,\n",
       " 'methods': 220,\n",
       " 'degenerate': 218,\n",
       " 'gamma': 218,\n",
       " 'dependence': 218,\n",
       " 'proof': 218,\n",
       " 'ruin': 218,\n",
       " 'simulation': 218,\n",
       " 'groups': 218,\n",
       " 'lipschitz': 216,\n",
       " 'detection': 216,\n",
       " 'equilibrium': 214,\n",
       " 'conditioned': 214,\n",
       " 'population': 214,\n",
       " 'scheme': 214,\n",
       " 'low': 214,\n",
       " 'lattice': 212,\n",
       " 'recurrence': 212,\n",
       " 'chaos': 212,\n",
       " 'almost': 210,\n",
       " 'potential': 210,\n",
       " 'information': 210,\n",
       " 'unbounded': 208,\n",
       " 'infinitely': 206,\n",
       " 'many': 204,\n",
       " 'expansion': 204,\n",
       " 'polynomial': 204,\n",
       " 'gibbs': 204,\n",
       " 'coupling': 204,\n",
       " 'universality': 204,\n",
       " 'mixed': 202,\n",
       " 'covariance': 202,\n",
       " 'immigration': 202,\n",
       " 'monotone': 198,\n",
       " 'variable': 198,\n",
       " 'behaviour': 198,\n",
       " 'upper': 198,\n",
       " 'log': 196,\n",
       " 'steins': 196,\n",
       " 'value': 196,\n",
       " 'tails': 196,\n",
       " 'bounded': 196,\n",
       " 'rank': 194,\n",
       " 'server': 194,\n",
       " 'dynamical': 192,\n",
       " 'euler': 192,\n",
       " 'switching': 192,\n",
       " 'edge': 192,\n",
       " 'construction': 192,\n",
       " 'forms': 192,\n",
       " 'eigenvalues': 190,\n",
       " 'environments': 190,\n",
       " 'k': 190,\n",
       " 'optimization': 190,\n",
       " 'joint': 190,\n",
       " 'kernels': 190,\n",
       " 'segmentation': 190,\n",
       " 'classification': 188,\n",
       " 'adaptive': 188,\n",
       " 'games': 188,\n",
       " 'modeling': 188,\n",
       " 'ensembles': 188,\n",
       " 'representations': 186,\n",
       " 'through': 186,\n",
       " 'degree': 186,\n",
       " 'decomposition': 184,\n",
       " 'robust': 184,\n",
       " 'transport': 184,\n",
       " 'mckean': 184,\n",
       " 'imaging': 184,\n",
       " 'metric': 182,\n",
       " 'birth': 182,\n",
       " 'domains': 180,\n",
       " 'algorithms': 180,\n",
       " 'size': 180,\n",
       " 'divisible': 180,\n",
       " 's': 180,\n",
       " 'product': 180,\n",
       " 'power': 180,\n",
       " 'bernoulli': 180,\n",
       " 'pdes': 178,\n",
       " 'expectations': 178,\n",
       " 'level': 178,\n",
       " 'occupation': 178,\n",
       " 'traffic': 178,\n",
       " 'complete': 178,\n",
       " 'volterra': 178,\n",
       " 'speed': 176,\n",
       " 'total': 176,\n",
       " 'expansions': 176,\n",
       " 'exclusion': 176,\n",
       " 'reconstruction': 176,\n",
       " 'vlasov': 176,\n",
       " 'queueing': 174,\n",
       " 'operator': 174,\n",
       " 'three': 174,\n",
       " 'limiting': 174,\n",
       " 'particles': 172,\n",
       " 'clt': 172,\n",
       " 'sided': 172,\n",
       " 'harnack': 170,\n",
       " 'explicit': 170,\n",
       " 'smooth': 168,\n",
       " 'cluster': 168,\n",
       " 'length': 168,\n",
       " 'pathwise': 168,\n",
       " 'perturbed': 168,\n",
       " 'wasserstein': 166,\n",
       " 'sure': 166,\n",
       " 'memory': 166,\n",
       " 'products': 166,\n",
       " 'feller': 166,\n",
       " 'prediction': 166,\n",
       " 'energy': 166,\n",
       " 'periodic': 166,\n",
       " 'extinction': 164,\n",
       " 'malliavin': 164,\n",
       " 'sharp': 164,\n",
       " 'correlation': 164,\n",
       " 'global': 164,\n",
       " 'block': 162,\n",
       " 'over': 162,\n",
       " 'death': 162,\n",
       " 'like': 162,\n",
       " 'delay': 162,\n",
       " 'doubly': 162,\n",
       " 'complex': 162,\n",
       " 'respect': 162,\n",
       " 'locally': 160,\n",
       " 'semigroups': 160,\n",
       " 'plane': 160,\n",
       " 'white': 160,\n",
       " 'single': 160,\n",
       " 'video': 160,\n",
       " 'vector': 158,\n",
       " 'monte': 158,\n",
       " 'carlo': 158,\n",
       " 'extremes': 158,\n",
       " 'are': 156,\n",
       " 'continuum': 156,\n",
       " 'harmonic': 156,\n",
       " 'efficient': 156,\n",
       " 'biased': 156,\n",
       " 'last': 156,\n",
       " '3d': 156,\n",
       " 'transient': 154,\n",
       " 'sub': 154,\n",
       " 'constant': 154,\n",
       " 'deterministic': 154,\n",
       " 'survival': 154,\n",
       " 'group': 154,\n",
       " 'principles': 154,\n",
       " 'manifolds': 154,\n",
       " 'integration': 152,\n",
       " 'regularization': 152,\n",
       " 'convolution': 152,\n",
       " 'statistical': 152,\n",
       " 'without': 152,\n",
       " 'domain': 152,\n",
       " 'quantitative': 152,\n",
       " 'half': 150,\n",
       " 'randomly': 150,\n",
       " 'values': 150,\n",
       " 'q': 150,\n",
       " 'sum': 150,\n",
       " 'expectation': 150,\n",
       " 'interaction': 150,\n",
       " 'loop': 150,\n",
       " 'exchangeable': 148,\n",
       " 'expected': 148,\n",
       " 'transform': 148,\n",
       " 'vectors': 148,\n",
       " 'binary': 148,\n",
       " 'distributed': 148,\n",
       " 'correlated': 148,\n",
       " 'square': 146,\n",
       " 'spin': 146,\n",
       " 'intersection': 144,\n",
       " 'compact': 144,\n",
       " 'banach': 144,\n",
       " 'propagation': 144,\n",
       " 'sde': 142,\n",
       " 'threshold': 142,\n",
       " 'ising': 142,\n",
       " 'fluid': 142,\n",
       " 'kac': 142,\n",
       " 'spectrally': 142,\n",
       " 'framework': 142,\n",
       " 'geometry': 142,\n",
       " 'sobolev': 140,\n",
       " 'initial': 140,\n",
       " 'maps': 140,\n",
       " 'numerical': 140,\n",
       " 'recurrent': 140,\n",
       " 'anderson': 140,\n",
       " 'result': 140,\n",
       " 'eigenvalue': 140,\n",
       " 'study': 140,\n",
       " 'sequence': 140,\n",
       " 'forward': 140,\n",
       " 'fixed': 138,\n",
       " 'averaging': 138,\n",
       " 'max': 138,\n",
       " 'hilbert': 136,\n",
       " 'duality': 136,\n",
       " 'filtering': 136,\n",
       " 'maxima': 136,\n",
       " 'generators': 136,\n",
       " 'wave': 136,\n",
       " 'subcritical': 136,\n",
       " 'slow': 136,\n",
       " 'extremal': 136,\n",
       " 'reversible': 134,\n",
       " 'wigner': 134,\n",
       " 'increments': 134,\n",
       " 'component': 134,\n",
       " 'logarithm': 134,\n",
       " 'shape': 134,\n",
       " 'ensemble': 134,\n",
       " 'reinforced': 134,\n",
       " 'bessel': 132,\n",
       " '3': 132,\n",
       " 'stokes': 132,\n",
       " 'constrained': 132,\n",
       " 'inverse': 132,\n",
       " 'structured': 132,\n",
       " 'version': 130,\n",
       " 'service': 130,\n",
       " 'fragmentation': 130,\n",
       " 'asymmetric': 130,\n",
       " 'fourier': 130,\n",
       " 'u': 128,\n",
       " 'de': 128,\n",
       " 'extreme': 128,\n",
       " 'urn': 128,\n",
       " 'recursive': 128,\n",
       " 'reaction': 128,\n",
       " 'support': 128,\n",
       " 'reflecting': 126,\n",
       " 'monotonicity': 126,\n",
       " 'higher': 126,\n",
       " 'affine': 126,\n",
       " 'or': 126,\n",
       " 'navier': 126,\n",
       " 'sle': 124,\n",
       " 'berry': 124,\n",
       " 'preferential': 124,\n",
       " 'attachment': 124,\n",
       " 'coalescent': 122,\n",
       " 'disorder': 122,\n",
       " 'index': 122,\n",
       " 'fleming': 122,\n",
       " 'viot': 122,\n",
       " 'older': 122,\n",
       " 'hyperbolic': 122,\n",
       " 'kolmogorov': 122,\n",
       " 'transience': 120,\n",
       " 'bridges': 120,\n",
       " 'near': 120,\n",
       " 'compression': 120,\n",
       " 'polymers': 118,\n",
       " 'extension': 118,\n",
       " 'supremum': 118,\n",
       " 'certain': 118,\n",
       " 'moving': 118,\n",
       " 'orthogonal': 118,\n",
       " 'vertex': 118,\n",
       " 'piecewise': 116,\n",
       " 'game': 116,\n",
       " 'revisited': 116,\n",
       " 'minimal': 116,\n",
       " 'norm': 116,\n",
       " 'hierarchical': 116,\n",
       " 'factorization': 116,\n",
       " 'elliptic': 114,\n",
       " 'polymer': 114,\n",
       " 'fluctuation': 114,\n",
       " 'independence': 114,\n",
       " 'transitions': 112,\n",
       " 'partitions': 112,\n",
       " 'perturbations': 112,\n",
       " 'cutoff': 112,\n",
       " 'esseen': 112,\n",
       " 'noises': 112,\n",
       " 'derivative': 112,\n",
       " 'well': 110,\n",
       " 'stein': 110,\n",
       " 'graphical': 110,\n",
       " 'weights': 110,\n",
       " 'counting': 110,\n",
       " 'interval': 110,\n",
       " 'quality': 110,\n",
       " 'erd': 110,\n",
       " 'lambda': 108,\n",
       " 'quantization': 108,\n",
       " 'nonparametric': 108,\n",
       " 'short': 108,\n",
       " 'estimate': 108,\n",
       " 'mass': 108,\n",
       " 'interactions': 108,\n",
       " 'hawkes': 108,\n",
       " 'discontinuous': 106,\n",
       " 'weakly': 106,\n",
       " 'view': 106,\n",
       " 'clusters': 104,\n",
       " 'open': 104,\n",
       " 'poincar': 104,\n",
       " 'transforms': 104,\n",
       " 'volume': 104,\n",
       " 'coupled': 104,\n",
       " 'generalization': 104,\n",
       " 'characteristic': 104,\n",
       " 'area': 102,\n",
       " 'spanning': 102,\n",
       " 'family': 102,\n",
       " 'media': 102,\n",
       " 'sensitivity': 102,\n",
       " 'dual': 102,\n",
       " 'volatility': 102,\n",
       " 'configuration': 102,\n",
       " 'boundaries': 100,\n",
       " 'excursion': 100,\n",
       " 'posedness': 100,\n",
       " 'largest': 100,\n",
       " 'truncated': 100,\n",
       " 'crossing': 100,\n",
       " 'resolution': 100,\n",
       " 'normalized': 100,\n",
       " 'feynman': 100,\n",
       " 'reduction': 100,\n",
       " 'schemes': 100,\n",
       " 'compound': 100,\n",
       " 'distances': 100,\n",
       " 'extended': 100,\n",
       " 'drifts': 98,\n",
       " 'how': 98,\n",
       " 'c': 98,\n",
       " 'coding': 98,\n",
       " 'epidemic': 98,\n",
       " 'logarithmic': 98,\n",
       " 'equivalence': 98,\n",
       " 'search': 96,\n",
       " 'fokker': 96,\n",
       " 'planck': 96,\n",
       " 'excited': 96,\n",
       " 'oriented': 96,\n",
       " 'universal': 96,\n",
       " 'examples': 96,\n",
       " 'light': 96,\n",
       " 'x': 96,\n",
       " 'couplings': 96,\n",
       " 'mixture': 96,\n",
       " 'persistence': 96,\n",
       " '0': 94,\n",
       " 'effect': 94,\n",
       " 'uncertainty': 94,\n",
       " 'parameters': 94,\n",
       " 't': 94,\n",
       " 'generated': 94,\n",
       " 'matching': 94,\n",
       " 'gap': 94,\n",
       " 'change': 94,\n",
       " 'coefficient': 94,\n",
       " 'binomial': 94,\n",
       " 'laplace': 94,\n",
       " 'sufficient': 94,\n",
       " 'hydrodynamic': 92,\n",
       " 'ballistic': 92,\n",
       " 'no': 92,\n",
       " 'voter': 92,\n",
       " 'multitype': 92,\n",
       " 'average': 92,\n",
       " 'asymptotically': 92,\n",
       " 'means': 92,\n",
       " 'divergence': 92,\n",
       " 'wishart': 92,\n",
       " 'sublinear': 92,\n",
       " 'analytic': 92,\n",
       " 'temperature': 92,\n",
       " 'mri': 92,\n",
       " 'semilinear': 90,\n",
       " 'approximate': 90,\n",
       " 'states': 90,\n",
       " 'derivatives': 90,\n",
       " 'perturbation': 90,\n",
       " 'langevin': 90,\n",
       " 'lyapunov': 90,\n",
       " 'homogenization': 90,\n",
       " 'ito': 90,\n",
       " 'classical': 90,\n",
       " 'criteria': 90,\n",
       " 'part': 90,\n",
       " 'exponent': 90,\n",
       " 'smoothing': 90,\n",
       " 'latent': 90,\n",
       " 'enyi': 90,\n",
       " 'neutral': 88,\n",
       " 'reflection': 88,\n",
       " 'that': 88,\n",
       " 'forest': 88,\n",
       " 'subordinators': 88,\n",
       " 'transportation': 88,\n",
       " 'cost': 88,\n",
       " 'hidden': 88,\n",
       " 'machine': 88,\n",
       " 'sequential': 88,\n",
       " 'estimators': 88,\n",
       " 'convolutional': 88,\n",
       " 'changed': 88,\n",
       " 'formulas': 88,\n",
       " 'fractal': 88,\n",
       " 'i.i.d': 86,\n",
       " 'boolean': 86,\n",
       " 'spherical': 86,\n",
       " 'tempered': 86,\n",
       " 'quantum': 86,\n",
       " 'aggregation': 86,\n",
       " 'pinning': 86,\n",
       " 'exponents': 86,\n",
       " 'components': 86,\n",
       " 'hurst': 86,\n",
       " 'killed': 86,\n",
       " 'constraints': 86,\n",
       " 'zeros': 86,\n",
       " 'not': 86,\n",
       " 'modulated': 86,\n",
       " 'populations': 84,\n",
       " 'jacobi': 84,\n",
       " 'cram': 84,\n",
       " 'metastability': 84,\n",
       " 'riemannian': 84,\n",
       " 'entries': 84,\n",
       " 'superprocesses': 84,\n",
       " 'among': 84,\n",
       " 'improved': 84,\n",
       " 'localization': 84,\n",
       " 'distributional': 84,\n",
       " 'double': 84,\n",
       " 'parallel': 84,\n",
       " 'liouville': 84,\n",
       " 'regularly': 84,\n",
       " 'fully': 84,\n",
       " 'decay': 82,\n",
       " 'hermitian': 82,\n",
       " 'coalescents': 82,\n",
       " 'laplacian': 82,\n",
       " 'indexed': 82,\n",
       " 'classes': 82,\n",
       " 'spectrum': 82,\n",
       " 'minimum': 82,\n",
       " 'tensor': 82,\n",
       " 'increasing': 80,\n",
       " 'burgers': 80,\n",
       " 'embedding': 80,\n",
       " 'semimartingales': 80,\n",
       " 'supervised': 80,\n",
       " 'form': 80,\n",
       " 'potentials': 80,\n",
       " 'skew': 80,\n",
       " 'height': 80,\n",
       " 'estimating': 80,\n",
       " 'spatially': 80,\n",
       " 'randomized': 80,\n",
       " 'beyond': 80,\n",
       " 'recovery': 80,\n",
       " 'variations': 78,\n",
       " 'stationarity': 78,\n",
       " 'arising': 78,\n",
       " 'modified': 78,\n",
       " 'connection': 78,\n",
       " 'permutations': 78,\n",
       " 'stratonovich': 78,\n",
       " 'observations': 78,\n",
       " 'feature': 78,\n",
       " 'precise': 78,\n",
       " 'loss': 76,\n",
       " 'optimality': 76,\n",
       " 'remarks': 76,\n",
       " 'tightness': 76,\n",
       " 'fisher': 76,\n",
       " 'tessellations': 76,\n",
       " 'skorokhod': 76,\n",
       " 'approximating': 76,\n",
       " 'rare': 76,\n",
       " 'absolute': 76,\n",
       " 'strategies': 76,\n",
       " 'canonical': 76,\n",
       " 'ball': 76,\n",
       " 'hard': 76,\n",
       " 'conjecture': 76,\n",
       " 'criticality': 76,\n",
       " 'transformation': 76,\n",
       " 'likelihood': 76,\n",
       " 'forests': 74,\n",
       " 'terms': 74,\n",
       " 'excursions': 74,\n",
       " 'arbitrary': 74,\n",
       " 'transformations': 74,\n",
       " '4': 74,\n",
       " 'euclidean': 74,\n",
       " 'hausdorff': 74,\n",
       " 'circle': 74,\n",
       " 'pure': 74,\n",
       " 'determinantal': 74,\n",
       " 'manifold': 74,\n",
       " 'isotropic': 74,\n",
       " 'performance': 74,\n",
       " 'identification': 74,\n",
       " 'given': 72,\n",
       " 'degrees': 72,\n",
       " 'families': 72,\n",
       " 'sharing': 72,\n",
       " 'steady': 72,\n",
       " 'difference': 72,\n",
       " 'capacity': 72,\n",
       " 'interlacements': 72,\n",
       " 'filter': 72,\n",
       " 'input': 72,\n",
       " 'up': 72,\n",
       " 'causal': 72,\n",
       " 'intensity': 72,\n",
       " 'constants': 70,\n",
       " 'splitting': 70,\n",
       " 'when': 70,\n",
       " 'unified': 70,\n",
       " 'bsde': 70,\n",
       " 'wright': 70,\n",
       " 'sheet': 70,\n",
       " 'filtration': 70,\n",
       " 'subordinate': 70,\n",
       " 'pseudo': 70,\n",
       " 'extensions': 70,\n",
       " 'term': 70,\n",
       " 'perfect': 70,\n",
       " 'cauchy': 70,\n",
       " 'os': 70,\n",
       " 'cover': 70,\n",
       " 'integrated': 70,\n",
       " 'strongly': 70,\n",
       " 'sensing': 70,\n",
       " 'terminal': 68,\n",
       " 'simultaneous': 68,\n",
       " 'anisotropic': 68,\n",
       " 'heterogeneous': 68,\n",
       " 'nearest': 68,\n",
       " 'regenerative': 68,\n",
       " 'bridge': 68,\n",
       " 'escape': 68,\n",
       " 'estimator': 68,\n",
       " 'map': 68,\n",
       " 'controlled': 68,\n",
       " 'types': 68,\n",
       " 'events': 68,\n",
       " 'kpz': 68,\n",
       " 'site': 68,\n",
       " 'sphere': 68,\n",
       " 'marked': 68,\n",
       " 'conductances': 68,\n",
       " 'chemical': 68,\n",
       " 'viscosity': 68,\n",
       " 'connected': 68,\n",
       " 'geodesics': 68,\n",
       " 'generative': 68,\n",
       " 'circular': 66,\n",
       " 'surface': 66,\n",
       " 'evolving': 66,\n",
       " 'cycle': 66,\n",
       " 'schr': 66,\n",
       " 'survey': 66,\n",
       " 'infinity': 66,\n",
       " 'necessary': 66,\n",
       " 'limited': 66,\n",
       " 'shortest': 66,\n",
       " 'multiscale': 66,\n",
       " 'color': 66,\n",
       " 'sigma': 64,\n",
       " 'effective': 64,\n",
       " 'characterizations': 64,\n",
       " 'convolutions': 64,\n",
       " 'correction': 64,\n",
       " 'ratio': 64,\n",
       " 'shot': 64,\n",
       " 'web': 64,\n",
       " 'common': 64,\n",
       " 'gi': 64,\n",
       " 'martin': 64,\n",
       " 'growing': 64,\n",
       " 'correlations': 64,\n",
       " 'coalescing': 64,\n",
       " 'towards': 64,\n",
       " 'taylor': 64,\n",
       " 'mixtures': 64,\n",
       " 'scalable': 64,\n",
       " 'frog': 64,\n",
       " 'ct': 64,\n",
       " 'ultrasound': 64,\n",
       " 'other': 62,\n",
       " 'smoothness': 62,\n",
       " 'skorohod': 62,\n",
       " 'neumann': 62,\n",
       " 'importance': 62,\n",
       " 'competing': 62,\n",
       " 'factor': 62,\n",
       " 'entropic': 62,\n",
       " 'catalytic': 62,\n",
       " 'curvature': 62,\n",
       " 'torus': 62,\n",
       " 'testing': 62,\n",
       " 'projections': 62,\n",
       " 'erased': 62,\n",
       " 'formulae': 62,\n",
       " 'b': 62,\n",
       " 'down': 62,\n",
       " 'full': 62,\n",
       " 'averages': 62,\n",
       " 'hamiltonian': 62,\n",
       " 'computation': 62,\n",
       " 'cox': 62,\n",
       " 'longest': 62,\n",
       " 'multilevel': 62,\n",
       " 'automatic': 62,\n",
       " 'assessment': 62,\n",
       " 'denoising': 62,\n",
       " 'tomography': 62,\n",
       " 'versus': 60,\n",
       " 'partition': 60,\n",
       " 'porous': 60,\n",
       " 'subexponential': 60,\n",
       " 'pairs': 60,\n",
       " 'abelian': 60,\n",
       " 'cut': 60,\n",
       " 'integers': 60,\n",
       " 'about': 60,\n",
       " 'edges': 60,\n",
       " 'principal': 60,\n",
       " 'irregular': 60,\n",
       " 'scenery': 60,\n",
       " 'differentiability': 60,\n",
       " 'structures': 60,\n",
       " 'balls': 60,\n",
       " 'urns': 60,\n",
       " 'mode': 60,\n",
       " 'diffusive': 60,\n",
       " 'bernstein': 60,\n",
       " 'unitary': 60,\n",
       " 'lattices': 60,\n",
       " 'bond': 60,\n",
       " 'optical': 60,\n",
       " 'ray': 60,\n",
       " 'different': 58,\n",
       " 'singularity': 58,\n",
       " 'nested': 58,\n",
       " 'standard': 58,\n",
       " 'integrability': 58,\n",
       " 'parts': 58,\n",
       " 'noisy': 58,\n",
       " 'mcmc': 58,\n",
       " 'all': 58,\n",
       " 'processing': 58,\n",
       " 'load': 58,\n",
       " 'intermittency': 58,\n",
       " 'nonnegative': 58,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fcb2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(dataset,path):\n",
    "    titles=dataset[\"title_pp\"].tolist()\n",
    "    abstracts=dataset[\"abstract_pp\"].tolist()\n",
    "    \n",
    "    titles_and_abstracts=list(zip(titles,abstracts))\n",
    "    titles_and_abstracts=list(map(lambda x: x[0] + \" -- \" + x[1],titles_and_abstracts))\n",
    "    titles_and_abstracts_write=\"\\n\\n\".join(titles_and_abstracts)\n",
    "    \n",
    "    with open(path,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(titles_and_abstracts_write)\n",
    "    titles_and_abstracts=[t_a.split() for t_a in titles_and_abstracts]\n",
    "    return titles_and_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "716fa1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_and_abstracts=convert_data(dataset,\"word2vec_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b011f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    sentences=titles_and_abstracts,\n",
    "    vector_size=300,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef7d55",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1b16024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(model,sentence,k=True):\n",
    "    if k:\n",
    "        sentence=preprocess(sentence)\n",
    "    sentence_=sentence.split()\n",
    "    embedding_list=[]\n",
    "    for token in sentence_:\n",
    "        try:\n",
    "            vec=model.wv[token]\n",
    "        except KeyError:\n",
    "            vec=np.zeros(model.vector_size)\n",
    "        embedding_list.append(vec)\n",
    "    embedding_pooled=np.mean(embedding_list,axis=0)\n",
    "    return embedding_pooled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff66e2e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.73760873e-01 -5.20296635e-01 -5.01851305e-01  7.62987988e-02\n",
      " -1.91133150e-01 -6.26178490e-01  4.06711838e-01  4.93630586e-01\n",
      " -3.13415440e-01 -2.03620845e-02  2.78329653e-01  1.72463433e-01\n",
      "  7.50194107e-02 -6.36856481e-02  2.60954084e-02  3.43899305e-02\n",
      "  3.81364284e-01 -1.85809734e-01  2.33950518e-01  6.32488963e-01\n",
      " -7.49104257e-02  3.98844076e-01  6.29321169e-01 -9.13951368e-02\n",
      "  4.10113147e-01 -5.49959847e-01 -1.03013090e-02  6.50639193e-02\n",
      "  1.73342230e-01 -9.80595840e-02 -8.56563284e-02  2.73359822e-01\n",
      " -1.31905183e-01  2.55335621e-01  1.13643527e-01  1.52305122e-01\n",
      " -5.41629206e-02  1.61376899e-01  4.24914803e-01 -2.70142561e-01\n",
      " -1.05499833e-01  6.80382601e-01  3.79985375e-01  1.98395134e-01\n",
      " -4.91785645e-01  1.16895034e-01 -1.01073282e+00  1.91197772e-01\n",
      " -2.30763623e-01  1.01822323e-01 -3.85627616e-01 -2.16322580e-01\n",
      "  6.42318257e-02 -5.73720455e-01  2.73620107e-02  2.84298633e-01\n",
      "  6.76350168e-02 -7.50132799e-02  6.60671858e-01 -1.63650498e-01\n",
      "  3.01675413e-02  4.77816501e-01  4.73702038e-01 -1.82280340e-01\n",
      "  2.34694481e-01  2.01520341e-01 -3.47668333e-01  5.59466630e-02\n",
      " -1.97464569e-01 -1.96424391e-01  1.06798066e-01  3.51322092e-01\n",
      " -2.78782614e-01  3.41189301e-02  3.13743792e-01 -4.68949043e-01\n",
      "  2.16682282e-01 -6.70838941e-02  1.25986261e-01 -1.13687645e-01\n",
      "  1.78485776e-01  4.57691765e-01  3.54943461e-01 -5.77948402e-01\n",
      "  3.54275512e-02 -7.10122019e-01  1.94826256e-01 -3.95235449e-01\n",
      " -6.47639162e-01 -6.89964800e-01 -3.44541841e-01  4.09354653e-02\n",
      " -4.93729929e-02 -1.05096746e-01  2.99708863e-01 -1.66558061e-01\n",
      "  6.84156161e-03 -2.47242460e-01 -1.66036231e-02 -5.27973026e-01\n",
      " -2.23527800e-01 -4.93636382e-01  4.13748303e-03 -3.31936679e-01\n",
      " -1.16518902e-01 -3.32732052e-02 -1.52049850e-01 -8.36909062e-02\n",
      "  1.11804877e-01 -1.37767516e-01  9.74193939e-02 -1.80355600e-01\n",
      "  1.11249637e-01 -2.01342307e-01 -2.86053779e-01 -2.04140465e-01\n",
      "  5.06477058e-01 -1.02723730e-02  1.43098292e-01 -5.79466486e-01\n",
      " -2.22262859e-01 -5.88999884e-01  4.17615618e-01 -2.85574436e-01\n",
      " -2.69542188e-02 -4.85500093e-01 -5.22805818e-01 -1.58618812e-02\n",
      " -2.61736473e-01 -1.53914204e-01 -2.23043707e-01 -4.54498576e-01\n",
      "  5.27310361e-02 -6.75580832e-02  5.64516289e-01 -1.91556971e-01\n",
      " -3.98182575e-01 -2.84846883e-02  4.85115222e-02 -1.05793131e-01\n",
      "  5.71589142e-01  2.78559542e-01 -9.82263651e-02  4.52538437e-01\n",
      " -5.39526173e-02 -4.58030269e-01  1.08273106e-01  6.52602005e-01\n",
      " -4.71340555e-01 -4.67075855e-02  5.48189761e-02  2.97354971e-01\n",
      " -7.38189412e-02  3.93037532e-01  1.38239762e-01 -1.39165451e-01\n",
      "  5.62750755e-01  7.15284348e-02  2.43912354e-01 -3.73313972e-01\n",
      " -3.38760150e-01 -2.08895747e-03 -2.66281526e-02 -4.29874165e-02\n",
      " -6.22231854e-02  1.59065645e-01  2.86051666e-01 -3.90308248e-01\n",
      "  3.74540563e-01 -3.41980838e-01 -1.21447782e-01  1.83536078e-01\n",
      "  3.95318567e-01  5.33041386e-01 -6.55271038e-01 -1.66922139e-01\n",
      " -2.73954777e-01  1.86501292e-01 -4.10686229e-01 -2.35093521e-01\n",
      " -5.36661720e-01  5.58069357e-01  5.96299657e-01  4.36440994e-02\n",
      " -3.11773909e-01  4.91682787e-01  2.13720462e-01 -1.17679230e-01\n",
      " -1.89881665e-02 -3.70268545e-02 -2.39845644e-01 -1.68944278e-01\n",
      "  3.65441896e-01  1.40932319e-01 -1.60287016e-01 -3.30068252e-01\n",
      " -2.74441153e-01 -8.74687093e-03  1.07208277e-01 -2.67554846e-03\n",
      "  4.96956487e-01  2.79159568e-01 -1.31132950e-01 -1.15861473e-01\n",
      "  1.19725612e-01  6.01033764e-01 -1.83997049e-01 -7.76952799e-01\n",
      " -7.58897300e-03 -6.70421061e-01 -2.97735115e-02 -1.25614379e-01\n",
      "  1.30271201e-01 -4.05952370e-01 -1.74218079e-01 -3.87960285e-01\n",
      "  1.83063700e-01  9.91929732e-03 -2.94981758e-01  2.17161015e-01\n",
      " -4.47309094e-01  2.08354922e-02 -1.73214025e-01  5.07164270e-01\n",
      " -2.22913265e-01 -5.58429022e-01 -1.32456522e-02 -2.82192060e-01\n",
      " -3.34937742e-01 -3.78422932e-01  1.55676763e-02 -9.71315163e-04\n",
      " -7.10528025e-03 -1.97682199e-01 -9.08482820e-03  2.87072481e-01\n",
      " -2.75042551e-01  1.21254231e-01  3.18880881e-01 -1.69816019e-01\n",
      " -1.37433625e-01 -4.31938436e-01 -6.36147431e-02  2.68971413e-01\n",
      "  7.99193121e-02  3.94076805e-01 -1.09446453e-02  1.92355544e-01\n",
      "  3.68178189e-02 -7.08301621e-02  3.99630457e-01 -1.78677359e-01\n",
      " -3.18193178e-01  2.38863251e-01 -5.61764096e-01  1.16491323e-01\n",
      " -2.40806273e-01  5.28638879e-01 -1.81387669e-01  2.44400165e-01\n",
      "  2.05422168e-01  7.11136247e-02 -3.35425671e-02 -2.24392331e-01\n",
      " -3.33512885e-01  6.45705277e-01 -4.03563531e-01 -1.22254555e-01\n",
      "  5.13726926e-01 -7.50979962e-02 -7.10191623e-02  2.77400398e-01\n",
      " -1.14281703e-01  4.03459569e-01  3.37967596e-01 -2.63223842e-01\n",
      " -4.10585846e-01 -4.72405834e-01  3.85255642e-01 -7.48241916e-02\n",
      " -1.79648052e-01 -2.16823352e-01 -5.65857674e-01  1.15143075e-01\n",
      "  3.76174265e-01 -2.07616213e-01  4.46760537e-01 -5.44572576e-01\n",
      " -4.42970682e-02  8.99470099e-01 -2.41344035e-01 -1.82398298e-02\n",
      " -3.99942713e-01 -8.85578234e-02 -1.11559948e-01 -3.41495450e-01\n",
      " -7.25668575e-01 -1.61818947e-01 -3.74232780e-01  5.71251230e-02]\n"
     ]
    }
   ],
   "source": [
    "print(get_sentence_vector(model,\"We give a quantitative analysis of clusterin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f5bec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_dotproduct(query_vector,embeddins,k):\n",
    "    similarity=(title_and_abstracs_embedding @ query_vector.T).squeeze(1)\n",
    "    topk=np.argpartition(similarity,-k)[-k:]\n",
    "    return topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70071ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4efc1ab645746e2bc0a935355d298a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def faiss_search(embeddings,query,k):\n",
    "    \n",
    "    index=faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(titles_and_abstracts_embedding)\n",
    "    query_vector=get_sentence_vector(model,query,False)[:,None].T\n",
    "    D,I=index.search(query_vector,k)\n",
    "    \n",
    "    return I\n",
    "titles_and_abstracts_embedding=[\n",
    "    get_sentence_vector(model,\" \".join(t_a),False)\n",
    "    for t_a in tqdm(titles_and_abstracts)\n",
    "]\n",
    "\n",
    "titles_and_abstracts_embedding=np.array(titles_and_abstracts_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10c73dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23025, 300)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_and_abstracts_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e27ff418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tencent video dataset tvd a video dataset for learning based visual data compression and analysis -- learning based visual data compression and analysis have attracted great interest from both academia and industry recently . more training as well as testing datasets especially good quality video datasets are highly desirable for related research and standardization activities . tencent video dataset tvd is established to serve various purposes such as training neural network based coding tools and testing machine vision tasks including object detection and tracking . tvd contains 86 video sequences with a variety of content coverage . each video sequence consists of 65 frames at 4k 3840x2160 spatial resolution . in this paper the details of this dataset as well as its performance when compressed by vvc and hevc video codecs are introduced .\n",
      "\n",
      "\n",
      "\n",
      "synthesizing dynamic mri using long term recurrent convolutional networks -- a method is proposed for converting raw ultrasound signals of respiratory organ motion into high frame rate dynamic mri using a long term recurrent convolutional neural network . ultrasound signals were acquired using a single element transducer referred to here as organ configuration motion ocm sensor while sagittal mr images were simultaneously acquired . both streams of data were used for training a cascade of convolutional layers to extract relevant features from raw ultrasound followed by a recurrent neural network to learn its temporal dynamics . the network was trained with mr images on the output and was employed to predict mr images at a temporal resolution of 100 frames per second based on ultrasound input alone without any further mr scanner input . the method was validated on 7 subjects .\n",
      "\n",
      "\n",
      "\n",
      "generative adversarial network based single pixel imaging -- single pixel imaging can reconstruct two dimensional images of a scene with only a single pixel detector . it has been widely used for imaging in non visible bandwidth e.g . near infrared and x ray where focal plane array sensors are challenging to be manufactured . in this paper we propose a generative adversarial network based reconstruction algorithm for single pixel imaging which demonstrates efficient reconstruction in 10ms and higher quality . we verify the proposed method with both synthetic and real world experiments and demonstrate a good quality of reconstruction of a real world plaster using a 0.05 sampling rate .\n",
      "\n",
      "\n",
      "\n",
      "instant image denoising plugin for imagej using convolutional neural networks -- we present a new convolutional neural network cnn based imagej plugin for fluorescence microscopy image denoising with an average improvement of 7.5 db in peak signal to noise ratio psnr and denoising instantly within 80 msec .\n",
      "\n",
      "\n",
      "\n",
      "stratify or inject two simple training strategies to improve brain tumor segmentation -- deep learning methods for brain tumor segmentation are typically trained in an ad hoc fashion on all available data . brain tumors are tremendously heterogeneous in image appearance and labeled training data is limited . we argue that incorporation of additional prior information specifically tumor grade associated with tumor imaging phenotypes during model training can significantly improve segmentation performance . two strategies for incorporation of tumor grade during model training are proposed and their impact on segmentation performance is demonstrated on the brats 2018 dataset .\n",
      "\n",
      "\n",
      "\n",
      "quantitative susceptibility mapping using deep neural network qsmnet -- deep neural networks have demonstrated promising potential for the field of medical image reconstruction . in this work an mri reconstruction algorithm which is referred to as quantitative susceptibility mapping qsm has been developed using a deep neural network in order to perform dipole deconvolution which restores magnetic susceptibility source from an mri field map . previous approaches of qsm require multiple orientation data e.g . calculation of susceptibility through multiple orientation sampling or cosmos or regularization terms e.g . truncated k space division or tkd morphology enabled dipole inversion or medi to solve the ill conditioned deconvolution problem . unfortunately they either require long multiple orientation scans or suffer from artifacts . to overcome these shortcomings a deep neural network qsmnet is constructed to generate a high quality susceptibility map from single orientation data . the network has a modified u net structure and is trained using gold standard cosmos qsm maps . 25 datasets from 5 subjects 5 orientation each were applied for patch wise training after doubling the data using augmentation . two additional datasets of 5 orientation data were used for validation and test one dataset each . the qsmnet maps of the test dataset were compared with those from tkd and medi for image quality and consistency in multiple head orientations . quantitative and qualitative image quality comparisons demonstrate that the qsmnet results have superior image quality to those of tkd or medi and have comparable image quality to those of cosmos . additionally qsmnet maps reveal substantially better consistency across the multiple orientations than those from tkd or medi . as a preliminary application the network was tested for two patients . the qsmnet maps showed similar lesion contrasts with those from medi demonstrating potential for future applications .\n",
      "\n",
      "\n",
      "\n",
      "image free real time classification of fast moving objects using learned spatial light modulation and a single pixel detector -- objects classification generally relies on image acquisition and analysis . real time classification of high speed moving objects is challenging as both high temporal resolution in image acquisition and low computational complexity in objects classification algorithms are required . here we propose and experimentally demonstrate an approach for real time moving objects classification without image acquisition . as objects classification algorithms rely on the feature information of objects we propose to use spatial light modulation to acquire the feature information directly rather than performing image acquisition followed by features extraction . a convolutional neural network is designed and trained to learn the spatial features of the target objects . the trained network can generate structured patterns for spatial light modulation . using the resulting structured patterns for spatial light modulation the feature information of target objects can be compressively encoded into a short light intensity sequence . the resulting one dimensional signal is collected by a single pixel detector and fed to the convolutional neural network for objects classification . as experimentally demonstrated the proposed approach can achieve accurate and real time classification of fast moving objects . the proposed method has potential applications in the fields where fast moving objects classification in real time and for long duration is required .\n",
      "\n",
      "\n",
      "\n",
      "strategies in jpeg compression using convolutional neural network cnn -- interests in digital image processing are growing enormously in recent decades . as a result different data compression techniques have been proposed which are concerned mostly with the minimization of information used for the representation of images . with the advances of deep neural networks image compression can be achieved to a higher degree . this paper describes an overview of jpeg compression discrete fourier transform dft convolutional neural network cnn quality metrics to measure the performance of image compression and discuss the advancement of deep learning for image compression mostly focused on jpeg and suggests that adaptation of model improve the compression .\n",
      "\n",
      "\n",
      "\n",
      "neural video compression using spatio temporal priors -- the pursuit of higher compression efficiency continuously drives the advances of video coding technologies . fundamentally we wish to find better predictions or priors that are reconstructed previously to remove the signal dependency efficiently and to accurately model the signal distribution for entropy coding . in this work we propose a neural video compression framework leveraging the spatial and temporal priors independently and jointly to exploit the correlations in intra texture optical flow based temporal motion and residuals . spatial priors are generated using downscaled low resolution features while temporal priors from previous reference frames and residuals are captured using a convolutional neural network based long short term memory convlstm structure in a temporal recurrent fashion . all of these parts are connected and trained jointly towards the optimal rate distortion performance . compared with the high efficiency video coding hevc main profile mp our method has demonstrated averaged 38 bjontegaard delta rate bd rate improvement using standard common test sequences where the distortion is multi scale structural similarity ms ssim .\n",
      "\n",
      "\n",
      "\n",
      "quality prediction on deep generative images -- in recent years deep neural networks have been utilized in a wide variety of applications including image generation . in particular generative adversarial networks gans are able to produce highly realistic pictures as part of tasks such as image compression . as with standard compression it is desirable to be able to automatically assess the perceptual quality of generative images to monitor and control the encode process . however existing image quality algorithms are ineffective on gan generated content especially on textured regions and at high compressions . here we propose a new naturalness based image quality predictor for generative images . our new gan picture quality predictor is built using a multi stage parallel boosting system based on structural similarity features and measurements of statistical similarity . to enable model development and testing we also constructed a subjective gan image quality database containing distorted gan images and collected human opinions of them . our experimental results indicate that our proposed gan iqa model delivers superior quality predictions on the generative image datasets as well as on traditional image quality datasets .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_index=faiss_search(titles_and_abstracts_embedding,\"multiple input cnn\",10)\n",
    "\n",
    "for idx in retrieved_index[0]:\n",
    "    print(\" \".join(titles_and_abstracts[idx]))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6102ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20029, 15157, 20312, 18535, 16934, 14520, 17536, 20980, 16173,\n",
       "       18180], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf582f",
   "metadata": {},
   "source": [
    "### Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "198fb539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "glove_vectors=gensim.downloader.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85fd91b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.8265538811683655),\n",
       " ('king', 0.7757720947265625),\n",
       " ('monarch', 0.5765542387962341),\n",
       " ('elizabeth', 0.549494743347168),\n",
       " ('throne', 0.5387357473373413),\n",
       " ('princess', 0.5265572667121887),\n",
       " ('majesty', 0.5183771252632141),\n",
       " ('royal', 0.5162538290023804),\n",
       " ('coronation', 0.5072318911552429),\n",
       " ('vi', 0.4976198375225067)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analogy(glove_vectors,ps1,p1,p2):\n",
    "    v=glove_vectors[ps1]-glove_vectors[p1] + glove_vectors[p2]\n",
    "    \n",
    "    return glove_vectors.most_similar(v)\n",
    "analogy(glove_vectors,\"king\",\"man\",\"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9dae519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('food', 0.7458261847496033),\n",
       " ('products', 0.579909086227417),\n",
       " ('software', 0.5337928533554077),\n",
       " ('supplies', 0.5279377102851868),\n",
       " ('goods', 0.5018188953399658),\n",
       " ('computers', 0.4913240373134613),\n",
       " ('product', 0.4814090430736542),\n",
       " ('equipment', 0.4810752868652344),\n",
       " ('programs', 0.4797922968864441),\n",
       " ('supply', 0.47966468334198)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(glove_vectors,\"software\",\"developer\",\"food\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167ce2b",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32fbf68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223f5412594c411f9923ec2109aa4912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91111765f5254838a73378e137e68d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93075209dbe4aae98c312f3a90adc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294f1c6e46a94f4b9792f0d194dfb9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/488k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954d7d8a067f49e99b988a21ff936f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf24e6ed7e1437589274fe6aeafc38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caad32d6be74b7eae4780c1e6a80165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=load_dataset(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53d40177",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "for sample in df[\"train\"]:\n",
    "    train.append([preprocess(sample[\"text\"]), sample[\"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "16f9e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "for sample in df[\"test\"]:\n",
    "    test.append([preprocess(sample[\"text\"]), sample[\"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b6f8e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5966334f03f140cabeea44ff356ccff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9596 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length=max([len(sample[0].split()) for sample in tqdm(train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a9180e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(glove_vectors,sentence,flag=False,pool=\"mean\",max_length=64):\n",
    "    if flag:\n",
    "        sentence=preprocess(sentence)\n",
    "    sentence_=sentence.split()\n",
    "    embedding_list=[]\n",
    "    for token in sentence_:\n",
    "        try:\n",
    "            vec=glove_vectors.get_vector(token)\n",
    "        except KeyError:\n",
    "            vec=np.zeros(glove_vectors.vector_size)\n",
    "        embedding_list.append(vec)\n",
    "    \n",
    "    if pool==\"mean\":\n",
    "        embedding_pooled=np.mean(embedding_list,axis=0)\n",
    "    elif pool==\"low_rank\":\n",
    "        if len(embedding_list)>max_length:\n",
    "            embedding_list=embedding_list[:max_length]\n",
    "        \n",
    "        elif len(embedding_list)<max_length:\n",
    "            for _ in range(max_length-len(embedding_list)):\n",
    "                vec=np.zeros(glove_vectors.vector_size)\n",
    "                embedding_list=append(vec)\n",
    "        embedding_pooled=np.concatenate(embedding_list,axis=0)\n",
    "    return embedding_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c45900bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2ac4058f964eefbc4f1ed5f2667edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9596 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f85f3fe1ec43b380248062e30835bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7b63b27f644ba0acdfd1270d49e41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9596 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5eb3a70ba684918aecf2f97bf30c5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool=\"mean\"\n",
    "X_train = [get_sentence_vector(glove_vectors, sample[0], pool=pool) for sample in tqdm(train)]\n",
    "X_train = np.stack(X_train, axis=0)\n",
    "\n",
    "X_test = [get_sentence_vector(glove_vectors, sample[0], pool=pool) for sample in tqdm(test)]\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "\n",
    "y_train = np.array([sample[1] for sample in tqdm(train)])\n",
    "y_test = np.array([sample[1] for sample in tqdm(test)])\n",
    "\n",
    "if pool == \"mean\":\n",
    "    svd = TruncatedSVD(n_components=50)\n",
    "    svd.fit(X_train)\n",
    "    \n",
    "    X_train = svd.transform(X_train)\n",
    "    X_test = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "790ca1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CatBoostClassifier(verbose=0)\n",
    "model.fit(X_train,y_train)\n",
    "preds=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ccd3e7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       533\n",
      "           1       0.93      0.89      0.91       533\n",
      "\n",
      "    accuracy                           0.91      1066\n",
      "   macro avg       0.91      0.91      0.91      1066\n",
      "weighted avg       0.91      0.91      0.91      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c0732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
